{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b76a816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcf459c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_choice(lst):\n",
    "    return random.choice(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a9d0863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 10000 lines in mnm_dataset.csv file\n"
     ]
    }
   ],
   "source": [
    "states = [\"CA\", \"WA\", \"TX\", \"NV\", \"CO\", \"OR\", \"AZ\", \"WY\", \"NM\", \"UT\"]\n",
    "colors = [\"Brown\", \"Blue\", \"Orange\", \"Yellow\", \"Green\", \"Red\"]\n",
    "fieldnames = ['State', 'Color', 'Count']\n",
    "\n",
    "\n",
    "entries = 10000\n",
    "dataset_fn = \"mnm_dataset.csv\"\n",
    "\n",
    "with open(dataset_fn, mode='w') as dataset_file:\n",
    "    dataset_writer = csv.writer(dataset_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    dataset_writer.writerow(fieldnames)\n",
    "    for i in range(1, entries):\n",
    "        dataset_writer.writerow([get_random_choice(states), get_random_choice(colors), random.randint(10, 100)])\n",
    "print(\"Wrote %d lines in %s file\" % (entries, dataset_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f19edd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb77604c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca1fb1f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/25 15:15:49 WARN Utils: Your hostname, Pauls-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.4.90 instead (on interface en0)\n",
      "22/11/25 15:15:49 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/25 15:15:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "+-----+------+-----+\n",
      "|State|Color |Count|\n",
      "+-----+------+-----+\n",
      "|AZ   |Red   |64   |\n",
      "|WY   |Red   |79   |\n",
      "|CO   |Yellow|91   |\n",
      "|NV   |Brown |76   |\n",
      "|CO   |Yellow|91   |\n",
      "+-----+------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----+------+----------+\n",
      "|State|Color |sum(Count)|\n",
      "+-----+------+----------+\n",
      "|WY   |Blue  |11612     |\n",
      "|CO   |Blue  |11226     |\n",
      "|NM   |Yellow|11028     |\n",
      "|OR   |Orange|10853     |\n",
      "|UT   |Green |10835     |\n",
      "|UT   |Red   |10830     |\n",
      "|AZ   |Brown |10395     |\n",
      "|NM   |Green |10215     |\n",
      "|OR   |Blue  |10187     |\n",
      "|CO   |Orange|10147     |\n",
      "|NV   |Orange|10107     |\n",
      "|WY   |Brown |10086     |\n",
      "|NV   |Red   |10066     |\n",
      "|WA   |Yellow|9990      |\n",
      "|NM   |Orange|9985      |\n",
      "|NM   |Blue  |9831      |\n",
      "|AZ   |Red   |9811      |\n",
      "|TX   |Yellow|9750      |\n",
      "|WY   |Yellow|9691      |\n",
      "|WY   |Orange|9682      |\n",
      "|WA   |Orange|9679      |\n",
      "|CO   |Green |9657      |\n",
      "|CA   |Brown |9586      |\n",
      "|CA   |Blue  |9546      |\n",
      "|WY   |Red   |9530      |\n",
      "|OR   |Green |9507      |\n",
      "|NM   |Red   |9460      |\n",
      "|TX   |Brown |9439      |\n",
      "|WA   |Green |9428      |\n",
      "|AZ   |Yellow|9418      |\n",
      "|NV   |Brown |9375      |\n",
      "|CO   |Brown |9347      |\n",
      "|UT   |Blue  |9308      |\n",
      "|WY   |Green |9123      |\n",
      "|AZ   |Orange|9108      |\n",
      "|NV   |Blue  |9043      |\n",
      "|CA   |Yellow|8916      |\n",
      "|TX   |Green |8883      |\n",
      "|NV   |Yellow|8662      |\n",
      "|UT   |Yellow|8563      |\n",
      "|UT   |Brown |8535      |\n",
      "|CO   |Yellow|8521      |\n",
      "|CA   |Red   |8468      |\n",
      "|WA   |Red   |8433      |\n",
      "|WA   |Blue  |8380      |\n",
      "|AZ   |Green |8352      |\n",
      "|TX   |Blue  |8345      |\n",
      "|TX   |Red   |8294      |\n",
      "|TX   |Orange|8225      |\n",
      "|AZ   |Blue  |8188      |\n",
      "|NV   |Green |8163      |\n",
      "|UT   |Orange|7984      |\n",
      "|CA   |Orange|7973      |\n",
      "|CA   |Green |7906      |\n",
      "|OR   |Brown |7891      |\n",
      "|WA   |Brown |7670      |\n",
      "|NM   |Brown |7669      |\n",
      "|OR   |Yellow|7622      |\n",
      "|OR   |Red   |7484      |\n",
      "|CO   |Red   |7194      |\n",
      "+-----+------+----------+\n",
      "\n",
      "Total Rows = 60\n",
      "+-----+------+----------+\n",
      "|State|Color |sum(Count)|\n",
      "+-----+------+----------+\n",
      "|CA   |Brown |9586      |\n",
      "|CA   |Blue  |9546      |\n",
      "|CA   |Yellow|8916      |\n",
      "|CA   |Red   |8468      |\n",
      "|CA   |Orange|7973      |\n",
      "|CA   |Green |7906      |\n",
      "+-----+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = (SparkSession\n",
    "    .builder\n",
    "    .appName(\"PythonMnMCount\")\n",
    "    .getOrCreate())\n",
    "\n",
    "\n",
    "# read the file into a Spark DataFrame\n",
    "mnm_df = (spark.read.format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .load(dataset_fn))\n",
    "\n",
    "mnm_df.show(n=5, truncate=False)\n",
    "\n",
    "# aggregate count of all colors and groupBy state and color\n",
    "# orderBy descending order\n",
    "count_mnm_df = (mnm_df.select(\"State\", \"Color\", \"Count\")\n",
    "                .groupBy([\"State\", \"Color\"])\n",
    "                .sum(\"Count\")\n",
    "                .orderBy(\"sum(Count)\", ascending=False))\n",
    "\n",
    "# show all the resulting aggregation for all the dates and colors\n",
    "count_mnm_df.show(n=60, truncate=False)\n",
    "print(\"Total Rows = %d\" % (count_mnm_df.count()))\n",
    "\n",
    "# find the aggregate count for California by filtering\n",
    "ca_count_mnm_df = (mnm_df.select(\"*\")\n",
    "                   .where(mnm_df.State == 'CA')\n",
    "                   .groupBy(\"State\", \"Color\")\n",
    "                   .sum(\"Count\")\n",
    "                   .orderBy(\"sum(Count)\", ascending=False))\n",
    "\n",
    "# show the resulting aggregation for California\n",
    "ca_count_mnm_df.show(n=10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b75d72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark 3.3 (Python 3.9)",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
